{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec945ff5",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604d895",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Settings\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cacb88",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d8208b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = \"data/heart_cleaned.csv\"\n",
    "OUTPUT_DIR = \"screenshots\"\n",
    "MODELS_DIR = \"models\"\n",
    "RESULTS_DIR = \"results\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Random state\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# MLflow setup\n",
    "EXPERIMENT_NAME = \"Heart-Disease-Classification-Notebook\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb11828",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a78cdc7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load cleaned dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7598508b",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c092b66",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ee3b0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = f\"{MODELS_DIR}/scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "print(\"✅ Feature scaling completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39593d",
   "metadata": {},
   "source": [
    "## 5. Model Training with MLflow - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409e865",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Logistic_Regression_Notebook\") as run:\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\\n\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"Logistic Regression\")\n",
    "    mlflow.log_param(\"n_samples\", len(df))\n",
    "    mlflow.log_param(\"n_features\", X.shape[1])\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"scaler\", \"StandardScaler\")\n",
    "    \n",
    "    # Hyperparameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear'],\n",
    "        'max_iter': [1000]\n",
    "    }\n",
    "    \n",
    "    # Grid search\n",
    "    lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "    grid = GridSearchCV(lr, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    # Log best parameters\n",
    "    for param, value in grid.best_params_.items():\n",
    "        mlflow.log_param(f\"best_{param}\", value)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    y_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "    \n",
    "    # Log metrics\n",
    "    for metric, value in metrics.items():\n",
    "        mlflow.log_metric(metric, value)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nResults:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Logistic Regression - Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    cm_path = f\"{OUTPUT_DIR}/lr_confusion_matrix_nb.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f\"ROC AUC = {metrics['roc_auc']:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - Logistic Regression')\n",
    "    plt.legend()\n",
    "    roc_path = f\"{OUTPUT_DIR}/lr_roc_curve_nb.png\"\n",
    "    plt.savefig(roc_path)\n",
    "    mlflow.log_artifact(roc_path)\n",
    "    plt.show()\n",
    "    \n",
    "    # Log model\n",
    "    signature = infer_signature(X_train_scaled, best_model.predict(X_train_scaled))\n",
    "    mlflow.sklearn.log_model(best_model, \"model\", signature=signature)\n",
    "    \n",
    "    print(\"\\n✅ Logistic Regression logged to MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8758272e",
   "metadata": {},
   "source": [
    "## 6. Model Training with MLflow - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90a8be",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Random_Forest_Notebook\") as run:\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\\n\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"Random Forest\")\n",
    "    mlflow.log_param(\"n_samples\", len(df))\n",
    "    mlflow.log_param(\"n_features\", X.shape[1])\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"scaler\", \"StandardScaler\")\n",
    "    \n",
    "    # Hyperparameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    # Grid search\n",
    "    rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "    grid = GridSearchCV(rf, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    # Log best parameters\n",
    "    for param, value in grid.best_params_.items():\n",
    "        mlflow.log_param(f\"best_{param}\", value)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    y_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "    \n",
    "    # Log metrics\n",
    "    for metric, value in metrics.items():\n",
    "        mlflow.log_metric(metric, value)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nResults:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
    "    plt.title('Random Forest - Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    cm_path = f\"{OUTPUT_DIR}/rf_confusion_matrix_nb.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f\"ROC AUC = {metrics['roc_auc']:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - Random Forest')\n",
    "    plt.legend()\n",
    "    roc_path = f\"{OUTPUT_DIR}/rf_roc_curve_nb.png\"\n",
    "    plt.savefig(roc_path)\n",
    "    mlflow.log_artifact(roc_path)\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature importance\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    sns.barplot(data=importance_df, x='importance', y='feature', palette='viridis')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    fi_path = f\"{OUTPUT_DIR}/rf_feature_importance_nb.png\"\n",
    "    plt.savefig(fi_path)\n",
    "    mlflow.log_artifact(fi_path)\n",
    "    plt.show()\n",
    "    \n",
    "    # Log model\n",
    "    signature = infer_signature(X_train_scaled, best_model.predict(X_train_scaled))\n",
    "    mlflow.sklearn.log_model(best_model, \"model\", signature=signature)\n",
    "    \n",
    "    print(\"\\n✅ Random Forest logged to MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85898d6f",
   "metadata": {},
   "source": [
    "## 7. View Experiments in MLflow UI\n",
    "\n",
    "Run the following command in terminal to view all experiments:\n",
    "\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "Then open: http://127.0.0.1:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e618e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **Completed:**\n",
    "- Feature engineering with StandardScaler\n",
    "- Two models trained (Logistic Regression & Random Forest)\n",
    "- Hyperparameter tuning with GridSearchCV\n",
    "- Cross-validation\n",
    "- Comprehensive metrics evaluation\n",
    "- **All experiments tracked with MLflow**\n",
    "\n",
    "**MLflow Logged:**\n",
    "- Parameters (dataset info, hyperparameters)\n",
    "- Metrics (accuracy, precision, recall, F1, ROC-AUC)\n",
    "- Artifacts (confusion matrices, ROC curves, feature importance)\n",
    "- Models (with signatures for deployment)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "csharp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
